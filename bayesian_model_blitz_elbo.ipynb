{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from blitz.modules import BayesianLinear\n",
    "from blitz.utils import variational_estimator\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr, pearsonr, kendalltau\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDUCE_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "sample_info = pd.read_csv(\"shared_data/cancer.samples\", sep=\"\\t\")[\n",
    "    [\"sample\", \"project_descriptor\", \"sample_type\"]\n",
    "]\n",
    "expression_df = (\n",
    "    pd.read_feather(\"shared_data/expression_df.feather\")\n",
    "    .drop([\"key\"], axis=1)\n",
    "    .transpose()\n",
    ")\n",
    "methylation_data_df = (\n",
    "    pd.read_feather(\"shared_data/methylation_data_df.feather\")\n",
    "    .drop([\"PMR_INDEX\"], axis=1)\n",
    "    .transpose()\n",
    ")\n",
    "sample_info = sample_info.set_index(\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_df = expression_df.join(sample_info, how=\"inner\")\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "project_descriptor_encoded = pd.get_dummies(\n",
    "    input_data_df[\"project_descriptor\"], prefix=\"cancer_type\"\n",
    ")\n",
    "sample_type_encoded = pd.get_dummies(input_data_df[\"sample_type\"], prefix=\"sample_type\")\n",
    "data_df = pd.concat(\n",
    "    [\n",
    "        input_data_df.drop([\"project_descriptor\", \"sample_type\"], axis=1),\n",
    "        project_descriptor_encoded,\n",
    "        sample_type_encoded,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Scale Data\n",
    "scaler = StandardScaler()\n",
    "# expression_scaled = scaler.fit_transform(data_df.values.astype(np.float64))\n",
    "expression_scaled = np.log1p(data_df.values.astype(np.float64))\n",
    "expression_data = torch.tensor(expression_scaled).float()\n",
    "meth_data = torch.tensor(methylation_data_df.values.astype(np.float64)).float() / 100\n",
    "expression_data = np.hstack([np.ones((expression_data.shape[0], 1)), expression_data])\n",
    "# Split Data\n",
    "expression_data_train, expression_data_test, meth_data_train, meth_data_test = (\n",
    "    train_test_split(expression_data, meth_data, test_size=0.33, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_data(x_data, y_data):\n",
    "    num_data = int(0.20 * len(x_data))\n",
    "    x_data_reduced = x_data[:num_data]\n",
    "    y_data_reduced = y_data[:num_data]\n",
    "    return x_data_reduced, y_data_reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REDUCE_DATA:\n",
    "    X_train, y_train = reduce_data(expression_data_train, meth_data_train)\n",
    "    X_test, y_test = reduce_data(expression_data_test, meth_data_test)\n",
    "else:\n",
    "    X_train, y_train = expression_data_train, meth_data_train\n",
    "    X_test, y_test = expression_data_test, meth_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_644466/481046610.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train, y_train = torch.tensor(X_train).float(), torch.tensor(y_train).float()\n",
      "/tmp/ipykernel_644466/481046610.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test, y_test = torch.tensor(X_test).float(), torch.tensor(y_test).float()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, y_train = torch.tensor(X_train).float(), torch.tensor(y_train).float()\n",
    "X_test, y_test = torch.tensor(X_test).float(), torch.tensor(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variational_estimator\n",
    "class BayesianRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, activation):\n",
    "        super().__init__()\n",
    "        # self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.blinear1 = BayesianLinear(input_dim, 512)\n",
    "        self.blinear2 = BayesianLinear(512, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        if activation == \"relu\":\n",
    "            self.activation_function = nn.ReLU()\n",
    "        else:\n",
    "            self.activation_function = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_ = self.activation_function(self.blinear1(x))\n",
    "        x_ = self.blinear2(x_)\n",
    "        return self.sigmoid(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression(regressor, X, y, samples=100, std_multiplier=2):\n",
    "    regressor.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = [regressor(X) for i in range(samples)]\n",
    "        preds = torch.stack(preds)\n",
    "        means = preds.mean(axis=0)\n",
    "        stds = preds.std(axis=0)\n",
    "        ci_upper = means + (std_multiplier * stds)\n",
    "        ci_lower = means - (std_multiplier * stds)\n",
    "        ic_acc = (ci_lower <= y) * (ci_upper >= y)\n",
    "        ic_acc = ic_acc.float().mean()\n",
    "    regressor.train()\n",
    "    return ic_acc, (ci_upper >= y).float().mean(), (ci_lower <= y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_put_size = y_train.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "dataloader_train = torch.utils.data.DataLoader(ds_train, batch_size=16, shuffle=True)\n",
    "\n",
    "ds_test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "dataloader_test = torch.utils.data.DataLoader(ds_test, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_losses(regressor, dataloader, criterion, optimizer_samples=10):\n",
    "    val_losses = []\n",
    "    regressor.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (datapoints, labels) in enumerate(dataloader):\n",
    "            loss = regressor.sample_elbo(\n",
    "                inputs=datapoints,\n",
    "                labels=labels,\n",
    "                criterion=criterion,\n",
    "                sample_nbr=optimizer_samples,\n",
    "            )\n",
    "            val_losses.append(loss.item())\n",
    "    regressor.train()\n",
    "    return np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.plot(np.arange(len(train_losses)), train_losses, label=\"Train Loss\")\n",
    "    plt.title(\"Linear Model Gene Expression to Methylaton\")\n",
    "\n",
    "    plt.xlabel(\"Train Time\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    x, val_loss = zip(*val_losses)\n",
    "    plt.plot(x, val_loss, label=\"Val Loss\")\n",
    "    plt.title(\"Linear Model Gene Expression to Methylaton\")\n",
    "\n",
    "    plt.xlabel(\"Train Time\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_vs_actual(model, valloader):\n",
    "    actual = []\n",
    "    predicted = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for expression, methylation in valloader:\n",
    "\n",
    "            expression, methylation = expression.to(device), methylation.to(device)\n",
    "            pred = model(expression)\n",
    "            actual.extend(methylation.cpu().numpy().flatten().tolist())\n",
    "            predicted.extend(pred.cpu().numpy().flatten().tolist())\n",
    "\n",
    "    pearson_corr, _ = pearsonr(actual, predicted)\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    # Plot the Results\n",
    "    plt.scatter(actual, predicted)\n",
    "    plt.xlabel(\"True Methylation Levels\")\n",
    "    plt.ylabel(\"Predicted Methylation Levels\")\n",
    "    plt.title(\"Neual Network Gene Expression Regressor Predictions vs True Values\")\n",
    "    plt.plot(\n",
    "        [min(actual), max(predicted)],\n",
    "        [min(actual), max(predicted)],\n",
    "        \"k--\",\n",
    "        lw=4,\n",
    "    )\n",
    "\n",
    "    x_text = min(actual) + (max(actual) - min(actual)) * 0.9\n",
    "    y_text = min(predicted) + (max(predicted) - min(predicted)) * 0.05\n",
    "\n",
    "    plt.text(\n",
    "        x_text,\n",
    "        y_text,\n",
    "        f\"MSE: {mse:.2f}\\nRÂ²: {r2:.2f}\\nPearson Correlation: {pearson_corr:.2f}\",\n",
    "        fontsize=12,\n",
    "    )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    dataloader_train, dataloader_test, epochs, learning_rate, optimizer_samples, val_every\n",
    "):\n",
    "    regressor = BayesianRegressor(input_size, out_put_size, \"tanh\")\n",
    "    optimizer = optim.SGD(regressor.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    iteration = 0\n",
    "    loop = tqdm(total=len(dataloader_train) * epochs)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        for i, (datapoints, labels) in enumerate(dataloader_train):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = regressor.sample_elbo(\n",
    "                inputs=datapoints,\n",
    "                labels=labels,\n",
    "                criterion=criterion,\n",
    "                sample_nbr=optimizer_samples,\n",
    "            )\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            last_val_loss = None\n",
    "\n",
    "            iteration += 1\n",
    "            if iteration % val_every == 0:\n",
    "                ic_acc, under_ci_upper, over_ci_lower = evaluate_regression(\n",
    "                    regressor, X_test, y_test, samples=25, std_multiplier=3\n",
    "                )\n",
    "                val_loss = get_val_losses(regressor, dataloader_test, criterion, optimizer_samples)\n",
    "                val_losses.append((len(train_losses), val_loss))\n",
    "                loop.set_description(\n",
    "                    \"CI acc: {:.2f}, CI upper acc: {:.2f}, CI lower acc: {:.2f}, \".format(\n",
    "                        ic_acc, under_ci_upper, over_ci_lower\n",
    "                    )\n",
    "                    + \"Train Loss: {:.4f}, Val Loss: {:.4f}\".format(loss, val_loss)\n",
    "                )\n",
    "            loop.update(1)\n",
    "    loop.close()\n",
    "    return regressor, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rates = [1e-3, 0.5e-3, 1e-4, 1e-5]\n",
    "optimizer_samples = [10, 50, 100, 1000]\n",
    "batch_sizes = [10, 50, 100]\n",
    "epochs = [20, 100, 1000, 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in learning_rates:\n",
    "    for opt_s in optimizer_samples:\n",
    "        for bs in batch_sizes:\n",
    "            for e in epochs:\n",
    "                print(\n",
    "                    f\"Learning Rate: {lr}, Optimizer Samples: {opt_s}, Batch Size: {bs}, Epochs: {e}\"\n",
    "                )\n",
    "                regressor, train_losses, val_losses = train(\n",
    "                    dataloader_train,\n",
    "                    dataloader_test,\n",
    "                    epochs=e,\n",
    "                    learning_rate=lr,\n",
    "                    optimizer_samples=opt_s,\n",
    "                    val_every=10,\n",
    "                )\n",
    "                pred_vs_actual(regressor, dataloader_test)\n",
    "                plot_losses(train_losses, val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jt_methylation_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
